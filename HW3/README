Joe Ellis and Jessica Ouyang
HW 3

FILES INCLUDED:
FreeBase/
    Api_Key.txt = The file that holds the api key for FreeBase
    pyFreeBase.py = Python Module for interacting with FreeBase

GoogleWebSearch/
    DownloadProfessorSites.py = Python Script for finding "About" webpages from the professors
    errors_downloading.txt = Any professors that we had errors downloading

RunProblem1.py = The program that runs problem 1 and creates an output file based on FreeBase search

famous_dates_train.txt = File holds the birth dates of famous people, used in training
famous_names_train.txt = File holds the names of famous people, used in training
famous_dates_test.txt = File holds the birth dates of famous people, used in testing
famous_dates_train.txt = File holds the birth names of famous people, used in testing
non_famous_birthdays.txt = File holds the birthdays of non-famous people used in training
non_famous_birthdays_test.txt = File holds the birthdays of non-famous people used in testing
non_famous_people.txt = File holds the names of non-famous people used in training
non_famous_people_test.txt = File holds the names of non-famous people used in testing

requirements.txt = The pip installer file for installing the necessary libraries

unstructured/
	evaluate.py
	get_dates.py
	predictions.txt	

structured/
    evaluate_stuct.py = Evaluate the result of structed data output
    predicted_train.txt = The predicted dates for the train set
    predicted_test.txt = The predicted dates of the test set

--------------------

COMPILATION:

All libraries used come directly with the python distribution except for BeautifulSoup4, which should be installed using
the pip installer.
    - When in the HW3 directory in the terminal type "pip install -r requirements.txt"

--------------------

RUNNING:

Structured Prediction:

- All commands should be run from the HW3 directory

1.) ./RunProblem1.py <name_file> <birth_date_file> <prediction_output_file>
    - Ex: "./RunProblem1.py famous_names_train.txt famous_dates_train.txt structured/predicted_train.txt"

2.) ./structured/evaluate_struct.py <gold_dates_file> <predicted_dates_file>
    - Ex: "./structured/evaluate_struct.py famous_dates_test.txt structured/predicted_test.txt"

Web Scraping:

- All commands should be run from the HW3 directory

1.) ./GoogleWebSearch <person_file>
    - No inputs for this function, all of the paths are hard coded, it will read in from

Unstructured prediction:

python unstructured/get_dates.py non_famous_people.txt non_famous_websites/
Optional third argument: year to use as default if unable to predict

python unstructured/evaluate.py non_famous_birthdays.txt unstructured/predictions.txt
This also outputs the average over gold labels.  The average from training can be used as the default year for testing (see above); otherwise the default is the average predicted year.

--------------------

TASK DESCRIPTION:

We used FreeBase for the structured data and professors' webpages for the unstructured data.  For the unstructured data, we got the gold labels from Wikipedia but did not use Wikipedia for predicting the birthdays.  As discussed with Andrew, we only predicted birth years and used 75 professors, with 60 for training and 15 for testing.

--------------------

EXPERIMENTS:

We achieve 26.67% accuracy on our test set.  Our main problem is that a lot of professors' websites don't say when they got their degrees on the main page.  Sometimes the information is on an "about me" or "biography" page, but sometimes it isn't on the website at all.  Even with the "about me" pages, there isn't any consistent way of naming those pages.  It would probably work better to download professors' CVs instead of using their websites, but then we would have to scrape the text out of the PDFs.

Right now we use a very simple and naive method for getting graduate dates from the websites: we search for degree words ("B.A.", "Ph.D", etc.) appearing near dates and assume that those dates refer to those degrees.  We find all dates, then check the line in which each date appears, the previous, and finally the following line.  We tried running Stanford CoreNLP on the webpages to clean the html, tokenize, and tag dates, but it took a very long time on some pages.

After extracting the graduation dates, we predict the birth year using very simple rules: we assume that everyone graduates from undergrad at 22 and then immediately starts either a 2-year masters or a 5-year PhD.  With more data, it would make more sense to learn age of graduation from the training set instead of using rules.  
