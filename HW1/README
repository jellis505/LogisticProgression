NLP, ML, and the Web 
Homework 1
Joe Ellis and Jessica Ouyang

--------------------

FILES INCLUDED:

web_srcaping/
	CleanHTMLPages.py - Python Functions and script
	CreateDesiredStructure.py - Python Functions and script
	GetChefPages.py - Python Functions and script
	non_used_files/
		- These files were not used, because we decided to use Java
		for the word representations.  Please do not grade, but they can
		be looked at if you desire.

ChefDetector/
	bin/ - Compiled Java .class files.
	build.xml - Ant buildfile.
	doc/ - Javadocs.
	lib/ - Library packages.
	     mallet-deps.jar
	     mallet.jar
	src/ - Java files.
	temp/ - Saved Mallet data structures (feature/label dictionaries, training/testing instances).  This is created by train.sh and must not be deleted or else test.sh will not be able to load the testing instances.
	test.sh - Testing script.
	train.sh - Training script.

--------------------

COMPILING:

web_scraping:
pip install -r requirements.txt
	- this command will automatically install the additionaly necessary libraries beyond what comes packaged
	with the base python distribution

ChefDetector:
ant clean - remove old bin/, doc/, and temp/
ant compile - generate .class files
ant javadoc - generate documentation

-------------------

RUNNING:

web_scraping:
CleanHTMLPages.py
	-Usage: ./CleanHTMLPages.py <top_level_directory containing the author directories>

GetChefPages.py
	-Usage: ./GetChefPages.py -i "<name to be searched>" -n <top_level_dir/author_name>

CreateDesiredStructure.py
	-Usage: ./CreateDesiredStructure.py <top_level_directory containing the author directories>

ChefDetector:
Command line arguments for train.sh:
1) Which representation to use (bagofwords, backoff, trigram).
2) Training label file.
3) Testing label file.
4) Data directory.
5) Filename for saving the trained model.
Command line arguments for test.sh:
1) Which representation to use (bagofwords, backoff, trigram).
2) Filename for the saved model.
3) Filename for output.

--------------------

TASK:

Web_Scraping:
We have chosen to try to classify recipes on FoodNetwork.com based on which famous chef came up with this particular recipe.  FoodNetwork is a great resource for many recipes and is widely utilized by many people.  
However, there is no very easy way to gain access to each of the recipes, as they are not organized by chef pages.  However, we can gain access to the recipes by using the website’s recipe search ability, and then filtering the results by chef.  The FoodNetwork also will only show 12 recipes per html page for a given search query, therefore we must iterate through the search results automatically, and extract the links to each recipe and then iterate through the results.  We have created a command line program that takes as input the name of the chef to search and filter FoodNetwork.com for, and downloads each of the html files for each recipe into a directory.  The url that is queried by the program is, http://www.foodnetwork.com/search/delegate.do?Nr=Record%20Type:Result&N=501%204294959872&fnSearchString=guy%20fieri&No=12, where this search finds the recipes created by “Guy Fieri” and returns the 12th to 24th recipe in the list.  We then parsed the html file to extract the links for each recipe’s html page.
After we had downloaded all of the recipes, we then moved on to extracting the recipe from the html page.  We have created a program that systematically removes the ingredients and directions from each html file, and outputs them to a plain-text file with the same name as the html file, but a .txt file extension.  To perform the parsing we used the python BeautifulSoup library

Representation and Classification:
Our goal was to classify recipes by chef.  We downloaded 200 recipes for each of 5 Food Network chefs: Bobby Flay, Giada de Laurentiis, Guy Fieri, Paula Deen, and Rachel Ray.  

We treated each recipe as three parts: the title, which usually lists the most important ingredients; the ingredients list, including ingredients that require preparation; and the instructions.  We represented the title with a bag of words.  The ingredients list was represented with features mapping ingredient names to the amounts used, as well as a single feature counting the number of ingredients that required preparation (for example, the ingredient "peach puree" came with the instructions "put peaches and ice in a blender, blend, etc").  These features did not change among experiments.

The three representations that we tested for the instructions were bag of words, a back-off bag of words (words appearing in fewer than 5 recipes were considered rare), and trigrams.  

--------------------

EXPERIMENTS:

We ran all experiments with MaxEnt in Mallet.  We chose MaxEnt because a highly-cited paper by David Madigan on author identification, which we thought might be similar to chef identification, used logistic regression.  

Using all features, all three representations achieved 99.8% accuracy on the test set.  

We tried feature ablation and got these results:
title - 95.4%
ingredients - 99.8%
instructions
      bag of words - 31.2%
      back-off - 25.4%	
      trigram - 28.6%

title and instructions
      bag of words - 96.2%
      back-off - 95.0%
      trigram - 95.6%


